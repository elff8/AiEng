"""
Pronunciation scoring with Conv1D + global StandardScaler
---------------------------------------------------------
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
    ‚Ä¢ <word>_model.h5   ‚Äì –≤–µ—Å–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
    ‚Ä¢ <word>_scaler.pkl ‚Äì –æ–±—É—á–µ–Ω–Ω—ã–π StandardScaler
"""

import os
import pickle
import numpy as np
import librosa
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.callbacks import EarlyStopping

# -------------------------  –ü–ê–†–ê–ú–ï–¢–†–´  -------------------------
SAMPLE_RATE = 16_000        # —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
MAX_LEN     = 50            # —á–∏—Å–ª–æ –∫–∞–¥—Ä–æ–≤ MFCC –Ω–∞ –∑–∞–ø–∏—Å—å
N_MFCC      = 13            # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ MFCC
DATA_DIR    = "DatasetAudio"
BATCH_SIZE  = 8
EPOCHS      = 50

# --------------------  –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò  ----------------
def extract_features(file_path: str) -> np.ndarray:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç wav, —Å—á–∏—Ç–∞–µ—Ç MFCC –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –¥–ª–∏–Ω—É –∫ MAX_LEN –∫–∞–¥—Ä–æ–≤.
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è ‚Äì —ç—Ç–∏–º –∑–∞–π–º—ë—Ç—Å—è –≥–ª–æ–±–∞–ª—å–Ω—ã–π scaler.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç ndarray —Ñ–æ—Ä–º—ã (MAX_LEN, N_MFCC).
    """
    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCC)  # (n_mfcc, time)

    # pad / truncate –¥–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã
    if mfcc.shape[1] < MAX_LEN:
        pad = MAX_LEN - mfcc.shape[1]
        mfcc = np.pad(mfcc, ((0, 0), (0, pad)), mode="constant")
    else:
        mfcc = mfcc[:, :MAX_LEN]

    return mfcc.T                     # (time, n_mfcc) = (MAX_LEN, N_MFCC)


def load_dataset_from_scored_subdirs(word_dir: str):
    """
    –ß–∏—Ç–∞–µ—Ç –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–∏ 0.0, 0.4, 0.8 ...,
    —Å–æ–±–∏—Ä–∞–µ—Ç X (MFCC) –∏ y (–æ—Ü–µ–Ω–∫—É –æ—Ç 0.0 –¥–æ 1.0).
    """
    X, y = [], []
    for score_dir in os.listdir(word_dir):
        path = os.path.join(word_dir, score_dir)
        if not os.path.isdir(path):
            continue
        try:
            score = float(score_dir.replace(",", "."))   # –Ω–∞ —Å–ª—É—á–∞–π 0,4
        except ValueError:
            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–∞ –ø–∞–ø–∫–∞: {score_dir} (–Ω–µ —á–∏—Å–ª–æ)")
            continue

        for fname in os.listdir(path):
            if not fname.endswith(".wav"):
                continue
            fpath = os.path.join(path, fname)
            X.append(extract_features(fpath))
            y.append(score)

    return np.array(X), np.array(y, dtype=np.float32)


def create_model() -> tf.keras.Model:
    """
    Conv1D ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool  (x2)
    ‚Üí GlobalAveragePooling ‚Üí Dense ‚Üí —Å–∏–≥–º–æ–∏–¥–∞.
    """
    inputs = tf.keras.layers.Input(shape=(MAX_LEN, N_MFCC))

    # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    x = tf.keras.layers.Conv1D(64, 5, padding="same", activation="relu")(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.MaxPooling1D(2)(x)

    # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
    x = tf.keras.layers.Conv1D(128, 5, padding="same", activation="relu")(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.MaxPooling1D(2)(x)

    # –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–∞–¥—Ä–∞–º
    x = tf.keras.layers.GlobalAveragePooling1D()(x)
    x = tf.keras.layers.Dropout(0.5)(x)

    # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
    x = tf.keras.layers.Dense(64, activation="relu")(x)
    x = tf.keras.layers.Dense(32, activation="relu")(x)
    outputs = tf.keras.layers.Dense(1, activation="sigmoid")(x)

    model = tf.keras.Model(inputs, outputs)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —è–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–æ—Ç–µ—Ä–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                  loss=tf.keras.losses.MeanSquaredError(),
                  metrics=[tf.keras.metrics.MeanAbsoluteError()])

    return model



# -------------------------  TRAIN & SAVE  ----------------------
def train_and_save_model(word: str):
    """
    ‚Ä¢ –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç `DatasetAudio/<word>/<score>/<wav>`
    ‚Ä¢ –û–±—É—á–∞–µ—Ç scaler –∏ –º–æ–¥–µ–ª—å
    ‚Ä¢ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç <word>_model.h5 –∏ <word>_scaler.pkl
    """
    word_dir = os.path.join(DATA_DIR, word)
    X, y = load_dataset_from_scored_subdirs(word_dir)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # ---------- –æ–±—É—á–∞–µ–º –µ–¥–∏–Ω—ã–π StandardScaler ----------
    scaler = StandardScaler()
    frames_for_scaler = X_train.reshape(-1, N_MFCC)        # (#frames, n_mfcc)
    scaler.fit(frames_for_scaler)

    # –ø—Ä–∏–º–µ–Ω—è–µ–º scaler –∫ train/test
    X_train = np.array([scaler.transform(x) for x in X_train])
    X_test  = np.array([scaler.transform(x) for x in X_test])

    # ---------- –º–æ–¥–µ–ª—å ----------
    model = create_model()
    early = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

    model.fit(X_train, y_train,
              epochs=EPOCHS,
              batch_size=BATCH_SIZE,
              validation_split=0.2,
              callbacks=[early],
              verbose=2)

    loss, mae = model.evaluate(X_test, y_test, verbose=0)
    print(f"MAE –¥–ª—è '{word}': {mae:.3f}")

    # ---------- —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ----------
    model.save(f"{word}_model.h5")
    with open(f"{word}_scaler.pkl", "wb") as f:
        pickle.dump(scaler, f)

    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {word}_model.h5  –∏  {word}_scaler.pkl")


# ---------------------------  PREDICT  -------------------------
def predict_word(model_path: str, scaler_path: str, audio_file: str):
    model = tf.keras.models.load_model(model_path)
    with open(scaler_path, "rb") as f:
        scaler: StandardScaler = pickle.load(f)

    feats = extract_features(audio_file)        # (MAX_LEN, N_MFCC)
    feats = scaler.transform(feats)             # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    feats = np.expand_dims(feats, axis=0)       # (1, MAX_LEN, N_MFCC)

    pred = model.predict(feats, verbose=0)[0][0]  # ‚àà [0, 1]
    score10 = round(pred * 10, 1)
    print(f"–ü—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ: {score10}/10")

    if score10 >= 8:
        print("üëç –•–æ—Ä–æ—à–æ")
    elif score10 >= 5:
        print("üòê –°—Ä–µ–¥–Ω–µ")
    else:
        print("üëé –ü–ª–æ—Ö–æ")


# ---------------------------  MAIN  ----------------------------
if __name__ == "__main__":
    words = ["apple", "blueberry"]    # <-- –≤–∞—à–∏ —Å–ª–æ–≤–∞

    for w in words:
        print(f"\n=== –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è ¬´{w}¬ª ===")
        train_and_save_model(w)

    # --- –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ---
    predict_word("blueberry_model.h5",
                 "blueberry_scaler.pkl",
                 r"C:\Users\wisp\PycharmProjects\AIEng\TestAudio\a2.wav")
